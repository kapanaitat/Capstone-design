import cv2
import numpy as np
import tensorflow as tf

# Load the trained TensorFlow model
model = tf.keras.models.load_model('traffic_light_detection_model.h5')

# Initialize the video capture device (e.g. Raspberry Pi camera)
cap = cv2.VideoCapture(0)

while True:
    # Capture a frame from the video stream
    ret, frame = cap.read()
    
    # Preprocess the image for input to the model
    input_image = cv2.resize(frame, (224, 224))
    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
    input_image = input_image.astype(np.float32) / 255.0
    input_image = np.expand_dims(input_image, axis=0)
    
    # Use the model to predict the location of the traffic light
    prediction = model.predict(input_image)
    
    # Extract the predicted bounding box and class label
    box = prediction[0]['bbox']
    label = prediction[0]['class']
    
    
      # Draw the predicted bounding box and class label on the frame
    x1, y1, x2, y2 = box
    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    # Display the annotated frame
    cv2.imshow('Traffic Light Detection', frame)
    
    # Exit the loop if the 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture device and close the window
cap.release()
cv2.destroyAllWindows()
